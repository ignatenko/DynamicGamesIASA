{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекція 1. Теорiя динамiчних iгор\n",
    "\n",
    "## Загальна інформація\n",
    "\n",
    "- 17 лекцiй, 8 практик, залiк.\n",
    "- практики: використання Python.\n",
    "- теоретичнi iгровi моделi та їх застосування у сучасному свiтi.\n",
    "- курс нещодавно створений, можливi будь-якi змiни.\n",
    "- самостiйна робота i iнiцiатива - очiкується i винагороджується\n",
    "\n",
    "## Викладач\n",
    "\n",
    "старший науковий співробітник, \n",
    "доктор фізико-математичних наук,\n",
    "провідний науковий співробітник Інституту програмних систем НАН України, \n",
    "доцент факультету інформатики НАУКМА,\n",
    "доцент кафедри ММСА\n",
    "Ігнатенко Олексій Петрович\n",
    "\n",
    "## Вимоги\n",
    "\n",
    "- базовий Пайтон (мати на ноуті середовище);\n",
    "- лекції змішані з практикою, будемо програмувати і перевіряти теорію;\n",
    "- 6 лабораторних робіт, 8 балів максимально, діє пониження максимального балу за здачу після дедлайну (48 балів);\n",
    "- індивідуальний проект. Перевірка результатів хорошої англомовної публікації. Результат - програма на Пайтоні + висновки (12 балів);\n",
    "- контрольна робота (15 балів);\n",
    "- іспит (25 балів).\n",
    "\n",
    "Для допуску до іспиту необхідно здати всі лаби і написати кр не нижче 7.\n",
    "\n",
    "## Комунікація\n",
    "\n",
    "- Всі лаби надсилайте на мейл o.ignatenko@gmail.com - час надсилання фіксується, можете здавати пізніше.\n",
    "- Телеграм канал, створюйте і надсилайте мені лінк.\n",
    "- лекції і практики будуть в репозиторії https://github.com/ignatenko/DynamicGamesIASA\n",
    "\n",
    "# План курсу\n",
    "\n",
    "1. Вступ до теорії ігор. Основні поняття, ідеї і області застосування. Теорія ігор, мультиагентні системи і машинне навчання.\n",
    "\n",
    "2. Ігри в нормальній формі.\n",
    "       2.1. Формулювання гри. Приклад: ігри в мережах. Обчислення ріноваги в іграх завантаження. \n",
    "       2.1. Рівновага Неша в чистих і змішаних стратегіях. Раціоналізація і домінуючі стратегії.\n",
    "       2.2. Алгоритми обчислення РН і їх складність. Алгоритм Лемке-Хоусона.\n",
    "3. Еволюція і навчання в іграх.\n",
    "        3.1. Динаміка найкращої відповіді. Метод уявної гри.\n",
    "        3.2. Мінімізація жалкування.\n",
    "        3.3. Еволюційні ігри.\n",
    "4. Ігри з повторенням.\n",
    "        4.1. Дилема в'язня.\n",
    "        4.2. Турніри Аксельрода.\n",
    "        4.3. Координаційні ігри.\n",
    "5. Ігри в розширеній формі.\n",
    "        5.1. Метод зворотної індукції.\n",
    "        5.2. Комбінаторні ігри і побудова дерев рішень.\n",
    "        5.3. Алгоритми розв'язання динамічних ігор.\n",
    "        5.5. Нім і його варіанти.\n",
    "        5.6. Теорема Шпрага-Грунді і її застосування.\n",
    "6. Ігри з неповною інформованістю.\n",
    "        6.1. Рівновага Байеса-Неша.\n",
    "7. Кооперативні ігри.\n",
    "        7.1. Ядро, вектор Шеплі, нуклеоси.\n",
    "        7.2. Метчінг. Алгоритми ТТС і Гейла-Шеплі.\n",
    "8. Аукціони.\n",
    "        8.1. Комбінаторні аукціони.\n",
    "        8.2. VCG механізми.\n",
    "        8.3. Аукціони Гугл.\n",
    "        8.3. Аукціони Прозорро і їх аналіз.\n",
    "\n",
    "## Джерела\n",
    "\n",
    "1. Azu Ozdaglar Game Theory with Engineering Applications\n",
    "2. Tim Rougharten Twenty lectures about Algorithmic game theory\n",
    "3. Vincent Knight https://vknight.org/gt/\n",
    "4. Thomas S. Ferguson Game Theory\n",
    "5. Michael H. Albert Richard J. Nowakowski David Wolfe Lessons in Play An Introduction to Combinatorial Game Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основні області використання:\n",
    "\n",
    "1. економіка.\n",
    "    - рівновага ринків.\n",
    "    - кооперативні рішення.\n",
    "    - аукціони.\n",
    "    - розробка оптимальних механізмів.\n",
    "2. соціальні науки.\n",
    "3. біологія.\n",
    "4. комп'ютерні науки.\n",
    "    - мережі.\n",
    "    - метчінги.\n",
    "    - реклама.\n",
    "    - пошук консенсусу (вікіпедія, Дебіан, Убунту).\n",
    "    - машинне навчання.\n",
    "---\n",
    "### Мета курсу\n",
    "\n",
    "- Вивчити ідеї і методи дослідження основних типів ігор.\n",
    "- Розглянути застосування моделей ТІ в різних галузях.\n",
    "- Імплементувати відомі алгоритми та продемонструвати їх роботу\n",
    "- (це все на Python)\n",
    "\n",
    "## Моделі теорії ігор\n",
    "\n",
    "**Взаємодiя** - термiн, що характеризує процеси практично у будь-якiй достатно складнiй системi. Говорячи про теорiю iгор ми, насамперед, маємо на увазi системи, що складаються з осiб здатних приймати рiшення. Це можуть бути люди, органiзацiї, держави i навiть, особливо останнiм часом, комп’ютернi програми. Надалi вiдносно таких осiб будемо використовувати термiн гравцi. Рiшення має наслiдком дiю гравця, яка впливає на стан системи. Такi ситуацiї називають *стратегiчною взаємодiєю* оскiльки гравець, який прагне дiяти з метою отримання найкращого для себе результату має зважувати на дiї iнших та враховувати їх iнтереси. Стратегiчна поведiнка, таким чином, має враховувати всi можливi дiї гравцiв, якi можуть вплинути на результат гри, та визначати власну дiю для кожної ситуацiї.\n",
    "\n",
    "## Шахи\n",
    "\n",
    "Модель шахів: \n",
    " - двоє гравців\n",
    " - відомі можливі дії для кожної позиції\n",
    " - гра скінченна: відомі умови закінчення.\n",
    " - повна іформованість.\n",
    " \n",
    " Можна побудувати дерево гри. \n",
    " \n",
    " Відомо, що існує одна з чотирьох стратегій: виграшна за білих, виграшна за чорних, нічийна за чорних або нічийна за білих.\n",
    " \n",
    "## Ефект кобри і інші проблеми\n",
    "\n",
    "\n",
    "1. Британська Індія. Кобри і індуси.\n",
    "2. Ханойські пацюки.\n",
    "3. Колумбія, Британія, кокаін.\n",
    "4. Пустеля, залізниця, верблюди.\n",
    "\n",
    "2012 рік. Олімпіада в Лондоні. Жіночий груповий бадмінтон. Найсильніша китайська команда (фаворити) програє данцям і займає друге місце в групі. Тепер все залежить від останнього матча в іншій групі - той хто виграє, потрапляє на фаворитів.\n",
    "\n",
    "Основна думка, яку варто підкреслити: правила визначають гру і рацональні гравці намагаються вигравати відповідно до правил. Це задача теорії ігор - визначити як вигравати.\n",
    "Задача **механізм дизайн** - визначити правила, щоб гравці вели себе \"прийнятно\".\n",
    "\n",
    "### Матчі на першість світу з шахів\n",
    "\n",
    "1. Турніри в кафе. Морфі. \n",
    "2. Офіційний матч з 12 - 40 партій. Чемпіон вибирає собі суперника (Стейніц, Ласкер)\n",
    "3. Капабланка: суперник має зібрати призовий фонд.\n",
    "4. Алехін - не грав з сильними суперниками.\n",
    "5. Суперник вибирається на турнірі. (починаючи з Ботвінніка) Нічия - чемпіон лишається. Право на матч-реванш.\n",
    "6. Зараз: серія партій зі зменшеним часом + Армагеддон.\n",
    "\n",
    "Інші приклади: Го.\n",
    "\n",
    "Курйози:\n",
    "1. Фішер-Петросян\n",
    "2. Німцович-Ласкер\n",
    "3. Карпов-Корчной\n",
    "\n",
    "## Теорія ігор, мультиагентні системи, штучний інтелект та машинне навчання. Який зв'язок?\n",
    "\n",
    "Штучний інтелект - парасоля, що накриває все пов'язане з імплементацією алгоритмів прийняття рішень (в складних умовах).\n",
    "\n",
    "Теорія ігор - математичне дослідження процесів прийняття рішень раціональними агентами. \n",
    "\n",
    "Машинне навчання - алгоритми, що добре працюють на основі існуючих даних. \n",
    "\n",
    "Мультиагентні системи - імплементація ідеї взаємодії агентів з метою (парадигма моделювання). \n",
    "\n",
    "**МАС - середовище в якому автономні раціональні агенти приймають рішення відповідно до алгоритмів машинного навчання щоб підтвердити або спростувати теоретичні результати, отримані за допомогою теорії ігор.** \n",
    "\n",
    "Сучасні тенденції: машинне навчання і теорія ігор змішуються для більш ефективної роботи.\n",
    "\n",
    "1. Використання МАС і навчання з теорією ігор. Розробка оптимальних механізмів на основі даних для ситуацій, коли аналітичне розв'язання складне.\n",
    "\n",
    "2. Використання теорії ігор для пояснення взаємодії алгоритмів машинного навчання. \n",
    "\n",
    "## Моделі\n",
    "\n",
    "Модель є спрощенням реальності. \n",
    "> **Всі моделі невірні, але деякі є корисними** \n",
    "---\n",
    "\n",
    "Модель, як правило, фокусується на головному аспекті явища. Можливі математичні, комп'ютерні (чисельні, імітаційні) моделі. \n",
    "Різні підходи до моделюванню дають різні результати. \n",
    "\n",
    "## Редукціонні і інтегруючі моделі \n",
    "\n",
    "Редукціонний Ньютонівський підхід:\n",
    "    - детерміністичний\n",
    "    - система уявлялась як машина (для сонячної системи спрацювало, для людей не дуже)\n",
    "    - ми можемо передбачити динаміку, якщо зрозуміємо роботу всіх внутрішніх механізмів\n",
    "    - прості закони, можливість зрозуміти складну динаміку\n",
    "    \n",
    "Інтегруючий підхід\n",
    "    - не можемо точно обчислити майбутню динаміку\n",
    "    - система постійно перебудовується відповідно до поточного стану і невеликих випадкових збурень. Хаос\n",
    "    - моделі змінюються відповідно до нашого сприйняття\n",
    "    - системи нестабільні, стохастичні\n",
    "    - система є наслідком накладення локальних дій багатоьох окремих сутностей (зграйність, натовп)\n",
    "    \n",
    "## Моделі: дедуктивний та індуктивний методи\n",
    "\n",
    "Індуктивна побудова - процес, який починається з огляду явища\n",
    "\n",
    "> Спостереження -> шаблон  -> гіпотеза  ->  теорія\n",
    "\n",
    "Дедуктивна побудова - процес, який йде у зворотному напрямку\n",
    "\n",
    "> Теорія  ->  гіпотези  ->  спостереження  -> підтвердження (або ні)\n",
    "\n",
    "## Агенто-орієнтоване моделювання\n",
    "\n",
    "Агентні моделі - це клас обчислювальних моделей для імітаційного моделювання \n",
    "дій та взаємодій агентів. Об'єднують ідеї (та використовуються для перевірки) теорії ігор, складних систем, МАС, еволюційного пограмування, машинного навчання.\n",
    "\n",
    "Характерні елементи:\n",
    "\n",
    "    - велика кількість агентів\n",
    "    - евристичні методи прийняття рішень\n",
    "    - навчання під час виконання\n",
    "    - наявність середовища\n",
    "    - складна система взаємодії\n",
    "\n",
    "як правило базуються на комп'ютерному моделюванні.\n",
    "\n",
    "## Iгри у нормальнiй (стратегiчнiй) формi\n",
    "\n",
    "Для визначення гри у стратегiчнiй формi потрiбно визначити три компонента: \n",
    "   - множина гравцiв.\n",
    "   - множина стратегій.\n",
    "   - функції виграшу.\n",
    "\n",
    "Некооперативною грою у стратегiчнiй формi називається трiйка $G = \\{ N , { S_i } , { u_i }\\}_{i \\in N}$ , де:\n",
    "    $N$ - скiнчена множина iндексiв гравцiв, $N = \\{ 1, ..., N \\}$;\n",
    "    $S_i$ - множина допустимих стратегiй $i$-го гравця;\n",
    "    $u_i : S → R$ - функцiя корисностi (виграшу) $i$-го гравця, де $S = S_1 × S_2 × ... × S_N$.\n",
    "    \n",
    "    \n",
    "## Приклади ігор\n",
    "\n",
    "### Гра № 1\n",
    "\n",
    "1. Оберiть число вiд 1 до 100. Кожен обирає ціле число $x_i$ .\n",
    "2. Обчислюємо $s = \\frac{1}{N}\\sum_1^N x_i$.\n",
    "3. Той, чиє число найближче до $\\frac{2}{3}s$ - перемiг.\n",
    "\n",
    "### Гра № 2\n",
    "\n",
    "1. Оберiть число вiд 1 до 100. Кожен обирає ціле число $x_i$ .\n",
    "2. Обчислюємо $s = \\frac{1}{N}\\sum_1^N x_i$.\n",
    "3. Той, чиє число найдалі від $s$ - перемiг.\n",
    "\n",
    "### Гра № 3\n",
    "\n",
    "1. Оберiть число вiд 1 до 100. Кожен обирає ціле число $x_i$ .\n",
    "2. Виграє число, яке назвали найбільше учасників. Якщо два числа отримали однакову кількість - перемагає менше з них.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1971 році Томас Шелінг опублікував роботу Динамічні моделі Сегрегації (Journal of Mathematical Sociology, 1971, Vol 1, pp 143–186). Він намагався зрозуміти чому так важко боротись з расовою сегрегацією в США. \n",
    "\n",
    "Гра, яка демонструє модель у простій формі: \n",
    "https://ncase.me/polygons/\n",
    "\n",
    "Модель дуже проста: \n",
    "\n",
    "1. Гра відбувається на двомірній сітці.\n",
    "2. Є два типи агентів, які можуть представляюти расу, дохід, статус.\n",
    "3. Кожен агент оцінює свій стан на основі локальної інформації (типів сусідів) і одного параметра \"щастя\".\n",
    "4. Нещасливі агенти змінюють своє місце (конкретні правила можуть вар'юватись).\n",
    "5. Гра продовжується поки є нащасливі агенти.    \n",
    "\n",
    "Результат, очевидно, залежить від щастя. Наприклад, правило \"Я хочу щоб всі мої сусіди були того ж типу, що і я\" призведе до повної сегрегації (якщо є місце). Але модель цікава тим, що невеликі зміни в правилах призводять до суттєвих змін результату (класична емерджентність). \n",
    "\n",
    "Преш Телвакар пише у своєму блозі: \n",
    "\n",
    "Модель Шелінга ідеалізована, але дає можливість зрозуміти сутність явища сегрегації і висвітлити неочевидні ідеї:\n",
    "\n",
    "1. Не вважайте всіх людей у \"білому\" районі расистами. \n",
    "    - невеликі уподобання можуть впливати з часом дуже сильно.\n",
    "\n",
    "2. Початкові умови мають значення.\n",
    "    - якщо ви хочете запобігти сегрегації потрібно починати з початку\n",
    "\n",
    "3. Для підтримання різноманітності потрібні зусилля. Іноді виїзд декількох сімей може призвести до сегрегації (це відбувається коли трапляється tipping point)\n",
    "    - в містечку-пригороді Чікаго Oak Park (яке є різноманітним) діють два правила: заборонено виставляти знаки \"продається\", місто пропонує страховку вартості будинку, яка гарантує, що вартість будинку не впаде через зміну сусідів. \n",
    "    \n",
    "4. Для порушення сегрегації потрібне втручання. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приклад. Сегрегаційна модель Шелінга\n",
    "Карта міста (Америка). Різні кольори - різні раси.\n",
    "\n",
    "### Чікаго\n",
    "![Chicago](./images/chicagodots_race_big_2010.jpg)\n",
    "\n",
    "Мікро-модель. Локальні правила, що формують поведінку кожного агента.\n",
    "![Правила моделі](./images/segreg-1.jpg)\n",
    "\n",
    "Результати моделювання.\n",
    "\n",
    "Початкове розташування.\n",
    "![Правила моделі](./images/schelling_2_initial.png)\n",
    "Фінальний розподіл\n",
    "![Правила моделі](./images/schelling_2_80_final.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/geraintpalmer/SchellingSegregationModel/blob/master/schelling.ipynb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette('PuOr')\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, x, y, kind, preference, world):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.kind = kind\n",
    "        self.preference = preference\n",
    "        self.world = world\n",
    "    \n",
    "    def know_neighbours(self):\n",
    "        self.neighbours = [self.world.coords[x % self.world.size, y % self.world.size]\n",
    "                           for x, y in itertools.product(range(self.x-1, self.x+2),\n",
    "                                                         range(self.y-1, self.y+2))]\n",
    "    \n",
    "    def swap(self, partner):\n",
    "        self.kind, partner.kind = partner.kind, self.kind\n",
    "    \n",
    "    def happiness(self):\n",
    "        neighbour_kinds = [n.kind for n in self.neighbours]\n",
    "        numsame = neighbour_kinds.count(self.kind)\n",
    "        numvacant = neighbour_kinds.count(0)\n",
    "        if numvacant == 8:\n",
    "            if self.vacant():\n",
    "                return 1.0\n",
    "            return 0.0\n",
    "        return (numsame - 1) / (8 - numvacant)\n",
    "    \n",
    "    def dissatisfied(self):\n",
    "        return self.happiness() < self.preference\n",
    "    \n",
    "    def vacant(self):\n",
    "        return self.kind == 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class World:\n",
    "    def __init__(self, size, kinds, probs, preference):\n",
    "        self.size = size\n",
    "        self.preference = preference\n",
    "        self.coords = self.populate_world(kinds, probs, preference)\n",
    "        [a.know_neighbours() for row in self.coords for a in row]\n",
    "        self.num_dissatisfied = size ** 2\n",
    "        self.num_vacant = sum([a.vacant() for row in self.coords for a in row])\n",
    "    \n",
    "    def populate_world(self, kinds, probs, preference):\n",
    "        return np.array([[Agent(x, y, np.random.choice(kinds, p=probs), preference, self)\n",
    "                          for y in range(self.size)] for x in range(self.size)])\n",
    "    \n",
    "    def atlas(self):\n",
    "        return np.array([[a.kind for a in row] for row in self.coords])\n",
    "    \n",
    "    def happiness_distribution(self):\n",
    "        return [a.happiness() for row in self.coords for a in row if not a.vacant()]\n",
    "    \n",
    "    def advance_turn(self):\n",
    "        dissatisfied = []\n",
    "        vacant = []\n",
    "        for row in self.coords:\n",
    "            for a in row:\n",
    "                if a.vacant():\n",
    "                    vacant.append(a)\n",
    "                elif a.dissatisfied():\n",
    "                    dissatisfied.append(a)\n",
    "        self.num_dissatisfied = len(dissatisfied)\n",
    "        np.random.shuffle(dissatisfied)\n",
    "        np.random.shuffle(vacant)\n",
    "        num_swap = min(self.num_dissatisfied, self.num_vacant)\n",
    "        for indx in range(num_swap):\n",
    "            dissatisfied[indx].swap(vacant[indx])\n",
    "    \n",
    "    def play(self, threshold=0.01):\n",
    "        while self.num_dissatisfied / (self.size ** 2) > threshold:\n",
    "            self.advance_turn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorldArchiving(World):\n",
    "    def __init__(self, size, kinds, probs, preference):\n",
    "        super(WorldArchiving, self).__init__(size, kinds, probs, preference)\n",
    "        self.archived_atlases = []\n",
    "    \n",
    "    def archive(self):\n",
    "        self.archived_atlases.append(copy.deepcopy(self.atlas()))\n",
    "\n",
    "    def play(self, threshold=0.01):\n",
    "        self.archive()\n",
    "        while self.num_dissatisfied / (self.size ** 2) > threshold:\n",
    "            self.advance_turn()\n",
    "            self.archive()\n",
    "\n",
    "def plot_atlas(w, turn):\n",
    "    num_turns = len(w.archived_atlases)\n",
    "    cmap = colors.ListedColormap(['white', '#FFCC1A', '#630081'])\n",
    "    fig, ax = plt.subplots(1, figsize=(11, 11))\n",
    "    ax.pcolor(w.archived_atlases[turn], cmap=cmap)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('atlas_' + str(turn))\n",
    "\n",
    "def number_connected_components(w):\n",
    "    temp = np.matrix(copy.deepcopy(w.atlas()))\n",
    "    nodes = ['(' + str(x) + ', ' + str(y) + ')' for x in range(w.size) for y in range(w.size) if temp[x, y] != 0]\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    for x in range(w.size):\n",
    "        for y in range(w.size):\n",
    "            if temp[(x+1) % w.size, y] != 0 and temp[x, y] != 0:\n",
    "                if temp[(x+1) % w.size, y] == temp[x, y]:\n",
    "                    G.add_edge('(' + str(x) + ', ' + str(y) + ')', '(' + str((x+1) % w.size) + ', ' + str(y) + ')')\n",
    "            if temp[x, (y+1) % w.size] != 0 and temp[x, y] != 0:\n",
    "                if temp[x, (y+1) % w.size] == temp[x, y]:\n",
    "                    G.add_edge('(' + str(x) + ', ' + str(y) + ')', '(' + str(x) + ', ' + str((y+1) % w.size) + ')')\n",
    "    return nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "np.random.seed(0)\n",
    "worlds = {str(round(pref, 4)): [World(40, [0, 1, 2], [0.1, 0.45, 0.45], pref) for trial in range(num_trials)] for pref in [i*0.01 for i in range(76)]}\n",
    "for k, trial in tqdm.tqdm(list(itertools.product(worlds, range(num_trials)))):\n",
    "    worlds[k][trial].play(threshold=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 4\n",
    "\n",
    "cmap = colors.ListedColormap(['white', '#FFCC1A', '#630081'])\n",
    "fig, axarr = plt.subplots(nrows=nrows, ncols=ncols, figsize=(22, 18))\n",
    "for i, k in enumerate(['0.2', '0.25', '0.3', '0.35', '0.4', '0.45', '0.5', '0.55', '0.6', '0.65', '0.7', '0.75',]):\n",
    "    axarr[i // ncols, i % ncols].pcolor(worlds[k][0].atlas(), cmap=cmap)\n",
    "    axarr[i // ncols, i % ncols].set_xticks([])\n",
    "    axarr[i // ncols, i % ncols].set_yticks([])\n",
    "    axarr[i // ncols, i % ncols].set_title('Щастя = ' + str(k), fontsize=34)\n",
    "plt.tight_layout()\n",
    "fig.savefig('increase_preference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Правила моделі](./images/output.png)\n",
    "\n",
    "## Анімація\n",
    "\n",
    "![Правила моделі](./images/atlas.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
